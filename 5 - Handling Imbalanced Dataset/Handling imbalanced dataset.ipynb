{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHÂN LỚP DỮ LIỆU KHÔNG CÂN BẰNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các bộ dữ liệu mẫu mà chúng ta thường sử dụng để thực hành các thuật toán phân loại thông thường đã được điều chỉnh để học viên dễ dàng tiếp cận được với thuật toán. Trong thực tế, dữ liệu thường không cân bằng giữa các lớp của biến số phụ thuộc (dependent variable / outcome / response / target /y) tức một lớp chiếm tỉ lệ rất lớn còn một hoặc các lớp còn lại một tỉ lệ rất nhỏ. Ví dụ dữ liệu về gian lận ngân hàng, dữ liệu phát hiện sự cố, dữ liệu chuẩn đoán trong y học đặc biệt đối với các bệnh hiếm.  \n",
    "Mất cân bằng dữ liệu làm giảm hiệu quả của các thuật toán phân loại, hầu hết các dữ liệu thuộc lớp đa số sẽ được đoán đúng còn lớp thiểu số sẽ bị đoán sai tuy nhiên độ chính xác tổng thể (accuracy) vẫn cao, ngay cả khi thuật toán dự đoán 100% thuộc lớp đa số thì độ chính xác tổng thể vẫn cao nhưng độ chính xác (recall) hay giá trị tiên đoán (precision) của một hoặc một số lớp sẽ rất thấp. Vấn đề này là một trong những vấn đề khó khăn trong xây dựng mô hình phân loại chính vì vậy ngoài phương pháp thu thập thêm mẫu cho lớp thiểu số thì cũng được các nhà khoa học đề xuất nhiều phương pháp. Các phương pháp này xếp thành 3 nhóm chính là:  \n",
    "- Tạo thêm các mẫu cho lớp thiểu số (Over-sampling), và\n",
    "- Giảm bớt các mẫu của lớp đa số (Under-sampling), và\n",
    "- Kết hợp thêm mẫu lớp thiểu số đồng thời giảm mẫu lớp đa số.\n",
    "![](image/over-under-sampling.png \"over-under-sampling\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tạo thêm mẫu cho lớp thiểu số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    980\n",
       "1     20\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cho tập mẫu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "hacide= pd.read_csv('data/hacide/hacide_train.csv', index_col= 0)\n",
    "hacide.cls.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với dữ liệu mất cân bằng mà số lượng của nhóm thiểu số cũng quá ít như vậy thì sẽ không còn cách nào khác ngoại trừ tạo thêm mẫu cho lớp thiểu số."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo thêm các mẫu ngẫu nhiên cho lớp thiểu số (Random over-sampling)  \n",
    "Phương pháp này tuy có thể giải quyết được vấn đề mất cân bằng dữ liệu nhưng nó có một số nhược điểm là ngoài tốn nhiều tài nguyên máy tính để tính toán (nhược điểm chung của nhóm Over-sampling) còn dễ gây ra hiện tượng quá khớp (mô hình dự đoán tốt trên tập huấn luyện mà không tốt trên tập kiểm định)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    980\n",
       "0    980\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hacide_0= hacide[hacide.cls == 0]\n",
    "hacide_1= hacide[hacide.cls == 1]\n",
    "\n",
    "hacide_1_choice= np.random.choice(hacide_1.index, replace= True, size= hacide_0.shape[0])\n",
    "hacide_1_resample= hacide_1.loc[hacide_1_choice,:]\n",
    "\n",
    "hacide_final= hacide_0.append(hacide_1_resample)\n",
    "hacide_final.cls.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Giảm mẫu của lớp đa số"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm phương pháp giảm mẫu của lớp đa số nhìn chung có nguy cơ làm mất đi một số thông tin mà các mẫu bị xóa bỏ đã thể hiện. Trong nhóm này chia thành 2 nhóm nhỏ đó là:\n",
    "- Tạo một lượng mẫu mới ít hơn ban đầu cho lớp đa số nhưng đảm bảo đại diện;\n",
    "- Lựa chọn giữ lại các mẫu đại diện cho lớp đa số.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cho tập mẫu\n",
    "churn= pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "churn.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giảm mẫu nhóm đa số ngẫu nhiên (Random under-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    1869\n",
       "No     1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_No= churn[churn.Churn == 'No']\n",
    "churn_Yes= churn[churn.Churn == 'Yes']\n",
    "\n",
    "churn_No_choice= np.random.choice(churn_No.index, replace= True, size= churn_Yes.shape[0])\n",
    "churn_No_resample= churn_No.loc[churn_No_choice,:]\n",
    "\n",
    "churn_final= churn_Yes.append(churn_No_resample)\n",
    "churn_final.Churn.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Thư viện imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thư viện imbalanced-learn tương thích với Scikit-learn có cung cấp nhiều phương pháp giảm mẫu, thêm mẫu và kết hợp để xử lý bộ mẫu mất cân bằng đồng thời cung cấp sẵn các thuật toán phân loại tối ưu cho mẫu mất cân bằng. Hướng dẫn sử dụng của thư viện này rất chi tiết và đầy đủ minh họa tại [https://imbalanced-learn.org/](https://imbalanced-learn.org/) hoặc mã nguồn tại [https://github.com/scikit-learn-contrib/imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn).  \n",
    "Các phương pháp và thuật toán mà thư viện imbalanced-learn hỗ trợ tại version 0.6.2 gồm:  \n",
    "![](image/imbalanced-learn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lưu ý:__ Các thuật toán lấy lại mẫu hầu hết sử dụng tính toán dựa trên khoảng cách vì vậy đều đòi hỏi các biến số ở dạng định lượng. Nếu không ở dạng định lượng cần đã hóa trước khi đưa vào thuật toán. Một số lớp hỗ trợ biến số phân loại là: random under sampling, random over sampling và SMOTENC (SMOTENC tương tự như SMOTE nhưng được tích hợp sẵn tính năng tự động tạo biến giả để tính toán và tự động đảo ngược lại nhãn ban đầu cho các biến phân loại)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Lấy thêm mẫu lớp thiểu số sử dụng lớp SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Một tập con của tập churn\n",
    "X1= churn[['gender', 'SeniorCitizen', 'tenure', 'MonthlyCharges', 'PaymentMethod']]\n",
    "y1= churn.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập X1 ban đầu: (7043, 5)\n",
      "Số lượng mỗi lớp trong tập y1 ban đầu: Counter({'No': 5174, 'Yes': 1869})\n",
      "Kích thước tập X1 sau khi lấy thêm mẫu: (10348, 5)\n",
      "Số lượng mỗi lớp trong tập y1 sau khi lấy thêm mẫu: Counter({'No': 5174, 'Yes': 5174})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "print('Kích thước tập X1 ban đầu:', X1.shape)\n",
    "print('Số lượng mỗi lớp trong tập y1 ban đầu:', Counter(y1))\n",
    "\n",
    "smnc = SMOTENC(categorical_features=[0, 4]) # Cần chỉ định vị trí cột biến số phân loại\n",
    "X1_smnc_res, y1_smnc_res= smnc.fit_resample(X1, y1)\n",
    "\n",
    "print('Kích thước tập X1 sau khi lấy thêm mẫu:', X1_smnc_res.shape)\n",
    "print('Số lượng mỗi lớp trong tập y1 sau khi lấy thêm mẫu:', Counter(y1_smnc_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Lấy thêm mẫu lớp thiểu số sử dụng lớp SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập X1 ban đầu: (7043, 5)\n",
      "Số lượng mỗi lớp trong tập y1 ban đầu: Counter({'No': 5174, 'Yes': 1869})\n",
      "Kích thước tập X1 sau khi mã hóa: (7043, 9)\n",
      "Kích thước tập X1 sau khi lấy thêm mẫu: (10348, 9)\n",
      "Số lượng mỗi lớp trong tập y1 sau khi lấy thêm mẫu: Counter({'No': 5174, 'Yes': 5174})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "print('Kích thước tập X1 ban đầu:', X1.shape)\n",
    "print('Số lượng mỗi lớp trong tập y1 ban đầu:', Counter(y1))\n",
    "\n",
    "categorical_features= ['gender', 'PaymentMethod']\n",
    "X1_categorical= X1[categorical_features]\n",
    "X1_continuous= X1.drop(columns= categorical_features)\n",
    "\n",
    "oh_encode= OneHotEncoder(handle_unknown= 'ignore', sparse= False)\n",
    "oh_encoder= oh_encode.fit(X1_categorical)\n",
    "X1_categorical= oh_encoder.transform(X1_categorical)\n",
    "\n",
    "dummies_features= oh_encoder.get_feature_names(categorical_features)\n",
    "X1_categorical= pd.DataFrame(X1_categorical, columns=  dummies_features)\n",
    "X1_encoded= X1_categorical.join(X1_continuous)\n",
    "print('Kích thước tập X1 sau khi mã hóa:', X1_encoded.shape)\n",
    "\n",
    "sm= SMOTE()\n",
    "X1_encoded_sm_res, y_sm_res= sm.fit_resample(X1_encoded, y1)\n",
    "print('Kích thước tập X1 sau khi lấy thêm mẫu:', X1_encoded_sm_res.shape)\n",
    "print('Số lượng mỗi lớp trong tập y1 sau khi lấy thêm mẫu:', Counter(y_sm_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi xử lý mất cân bằng dữ liệu nếu như thuật toán học máy không hỗ trợ các biến phân loại thì chúng ta có thể tiếp tục sử dụng tập dữ liệu sau khi lấy thêm mẫu tuy nhiên các thuật toán học máy có hỗ trợ biến phân loại chúng ta có thể sẽ cần gán nhãn lại cho các biến phân loại. Các thuật toán lấy mẫu không hỗ trợ biến số phân loại khác cũng có thể sử dụng như dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập X1 sau khi gán lại nhãn: (10348, 5)\n"
     ]
    }
   ],
   "source": [
    "X1_sm_res= oh_encoder.inverse_transform(X1_encoded_sm_res[dummies_features])\n",
    "X1_sm_res= pd.DataFrame(X1_sm_res, columns= categorical_features)\n",
    "X1_sm_res= X1_sm_res.join(X1_encoded_sm_res.drop(columns= dummies_features))\n",
    "\n",
    "print('Kích thước tập X1 sau khi gán lại nhãn:', X1_sm_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Giảm mẫu lớp đa số sử dụng NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập X1 ban đầu: (7043, 5)\n",
      "Số lượng mỗi lớp trong tập y1 ban đầu: Counter({'No': 5174, 'Yes': 1869})\n",
      "Kích thước tập X1 sau khi mã hóa: (7043, 9)\n",
      "Kích thước tập X1 sau khi lấy thêm mẫu: (3738, 9)\n",
      "Số lượng mỗi lớp trong tập y1 sau khi lấy thêm mẫu: Counter({'No': 1869, 'Yes': 1869})\n",
      "Kích thước tập X1 sau khi gán lại nhãn: (3738, 5)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "print('Kích thước tập X1 ban đầu:', X1.shape)\n",
    "print('Số lượng mỗi lớp trong tập y1 ban đầu:', Counter(y1))\n",
    "\n",
    "categorical_features= ['gender', 'PaymentMethod']\n",
    "X1_categorical= X1[categorical_features]\n",
    "X1_continuous= X1.drop(columns= categorical_features)\n",
    "\n",
    "oh_encode= OneHotEncoder(handle_unknown= 'ignore', sparse= False)\n",
    "oh_encoder= oh_encode.fit(X1_categorical)\n",
    "X1_categorical= oh_encoder.transform(X1_categorical)\n",
    "\n",
    "dummies_features= oh_encoder.get_feature_names(categorical_features)\n",
    "X1_categorical= pd.DataFrame(X1_categorical, columns=  dummies_features)\n",
    "X1_encoded= X1_categorical.join(X1_continuous)\n",
    "print('Kích thước tập X1 sau khi mã hóa:', X1_encoded.shape)\n",
    "\n",
    "nm = NearMiss()\n",
    "X1_encoded_nm_res, y1_nm_res= nm.fit_resample(X1_encoded, y1)\n",
    "\n",
    "print('Kích thước tập X1 sau khi lấy thêm mẫu:', X1_encoded_nm_res.shape)\n",
    "print('Số lượng mỗi lớp trong tập y1 sau khi lấy thêm mẫu:', Counter(y1_nm_res))\n",
    "\n",
    "X1_mm_res= oh_encoder.inverse_transform(X1_encoded_nm_res[dummies_features])\n",
    "X1_mm_res= pd.DataFrame(X1_mm_res, columns= categorical_features)\n",
    "X1_mm_res= X1_mm_res.join(X1_encoded_nm_res.drop(columns= dummies_features))\n",
    "\n",
    "print('Kích thước tập X1 sau khi gán lại nhãn:', X1_mm_res.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
